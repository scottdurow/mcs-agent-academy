<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d6706e107678264168d77b2e107710b1",
  "translation_date": "2025-10-17T19:13:46+00:00",
  "source_file": "docs/recruit/01-introduction-to-agents/README.md",
  "language_code": "de"
}
-->
# ğŸš¨ Mission 01: EinfÃ¼hrung in Agenten

## ğŸ•µï¸â€â™‚ï¸ CODENAME: `OPERATION AI AGENT DECODE`

> **â±ï¸ Zeitfenster der Operation:** `~30 Minuten â€“ nur Informationen, keine Feldarbeit erforderlich`

ğŸ¥ **Schauen Sie sich die Anleitung an**

[![EinfÃ¼hrung in Agenten Video Thumbnail](../../../../../translated_images/video-thumbnail.56c0520a784a1a84608827574db5010a6f965836fb120255de402d20f2259f15.de.jpg)](https://www.youtube.com/watch?v=BhPz_zicUnM "Schauen Sie sich die Anleitung auf YouTube an")

## ğŸ¯ Missionsbriefing

Willkommen, Rekrut. Bevor wir mit dem Aufbau von Agenten beginnen, benÃ¶tigen Sie ein solides VerstÃ¤ndnis der KI-Konzepte, die sie antreiben. Diese Mission vermittelt Ihnen grundlegendes Wissen Ã¼ber konversationelle KI, groÃŸe Sprachmodelle (LLMs), Retrieval-Augmented Generation (RAG) und die Arten von Agenten, die Sie in Copilot Studio erstellen kÃ¶nnen.

## ğŸ” Ziele

In dieser Mission lernen Sie:

1. Was konversationelle KI ist und warum sie wichtig ist  
1. Wie groÃŸe Sprachmodelle (LLMs) Chat-Erlebnisse ermÃ¶glichen  
1. Was Retrieval-Augmented Generation (RAG) zu bieten hat  
1. Den Unterschied zwischen konversationellen und autonomen Agenten  
1. Wie Agenten in Copilot Studio diese Konzepte nutzen  

Legen wir los!

---

## Was ist konversationelle KI?

Konversationelle KI bezeichnet jedes System, das menschliche Sprache â€“ sei es Text oder Sprache â€“ verstehen, verarbeiten und darauf reagieren kann, und zwar auf eine Weise, die sich natÃ¼rlich anfÃ¼hlt. Denken Sie an Chatbots in Helpdesks oder virtuelle persÃ¶nliche Assistenten in Ihren Lieblings-Apps. Im Hintergrund basieren die meisten modernen konversationellen KIs auf groÃŸen Sprachmodellen (LLMs), die wir als NÃ¤chstes behandeln.

### Warum es wichtig ist

- **Benutzererfahrung:** Konversationelle Schnittstellen sind oft intuitiver als das Durchklicken von MenÃ¼s.  
- **Skalierbarkeit:** Ein Agent kann Dutzende oder Hunderte von gleichzeitigen GesprÃ¤chen fÃ¼hren.  
- **Effizienz:** Anstatt benutzerdefinierte regelbasierte Skripte zu erstellen, passen sich LLM-gesteuerte Agenten flexibel an Benutzereingaben an.  
- **Erweiterbarkeit:** Mit dem richtigen Design kÃ¶nnen Agenten auf Wissensdatenbanken zugreifen, APIs verbinden oder als â€digitale Kollegenâ€œ in GeschÃ¤ftsablÃ¤ufen agieren.

---

## GroÃŸe Sprachmodelle (LLMs) 101

Im Kern der meisten konversationellen KI-Systeme stehen **groÃŸe Sprachmodelle** â€“ neuronale Netzwerke, die auf riesigen Textkorpora trainiert werden. Sie lernen statistische Muster der Sprache, um kohÃ¤rente SÃ¤tze zu generieren, Fragen zu beantworten oder sogar Ideen zu entwickeln. Wichtige Punkte, die Sie verstehen sollten:

1. **Trainingsdaten:** LLMs verarbeiten Terabytes an Text (Webseiten, BÃ¼cher, Artikel). Dieses â€Weltwissenâ€œ ermÃ¶glicht es ihnen, auf viele Themen zu antworten.  
1. **Tokenisierung:** Text wird in kleinere Einheiten namens Tokens zerlegt (WÃ¶rter, TeilwÃ¶rter oder Zeichen). Das Modell sagt ein Token nach dem anderen voraus.  
1. **Kontextfenster:** Jedes LLM hat eine Grenze, wie viele Tokens es gleichzeitig â€sehenâ€œ kann. Ãœber diese Grenze hinaus werden frÃ¼here Tokens abgeschnitten.  
1. **Prompting:** Sie interagieren mit einem LLM, indem Sie ihm einen Prompt senden. Je besser Ihr Prompt, desto fokussierter und relevanter die Antwort.  
1. **Zero-shot vs. Fine-tuning:** Zero-shot bedeutet, ein LLM so zu verwenden, wie es ist (nur rohe Gewichte). Fine-tuning bedeutet, das Modell mit domÃ¤nenspezifischen Daten anzupassen, damit es genauer auf Ihre BedÃ¼rfnisse antwortet.

!!! Tip "Profi-Tipp"
    Ein hÃ¤ufig verwendeter Vergleich ist, dass ein LLM wie eine â€superintelligente AutovervollstÃ¤ndigungâ€œ ist. Es versteht die Bedeutung nicht wirklich wie ein menschliches Gehirn, aber es ist extrem gut darin, das nÃ¤chste beste Wort (oder die nÃ¤chste Phrase) in einer Sequenz vorherzusagen.

---

## Retrieval-Augmented Generation (RAG)

Wenn LLMs ausschlieÃŸlich auf statische Trainingsdaten angewiesen sind, kÃ¶nnen sie Halluzinationen erzeugen oder veraltet sein. RAG lÃ¶st dieses Problem, indem es dem Modell ermÃ¶glicht, aktuelle Informationen â€nachzuschlagenâ€œ, bevor es eine Antwort erstellt. Auf hoher Ebene funktioniert RAG so:

1. **Benutzeranfrage:** Ein Benutzer stellt eine Frage (z. B. â€Was gibt es Neues zu den Quartalsergebnissen von Contoso?â€œ).  
1. **Retriever-Schritt:** Das System durchsucht eine Wissensquelle (Dokumente, interne Datenbanken, SharePoint-Bibliotheken usw.), um relevante Passagen zu finden.  
1. **Erweiterung:** Die abgerufenen Passagen werden dem LLM-Prompt hinzugefÃ¼gt oder vorangestellt.  
1. **Generierung:** Das LLM verarbeitet sowohl die Frage des Benutzers als auch den abgerufenen Kontext und erstellt eine Antwort, die auf aktuellen Daten basiert.  

Mit RAG kann Ihr Agent interne Unternehmenswikis, Plugin-APIs oder eine FAQ-Wissensdatenbank durchsuchen und Antworten liefern, die nicht auf statisch verÃ¶ffentlichten Modellparametern beschrÃ¤nkt sind.

---

## Konversationelle vs. autonome Agenten

Im Kontext von Copilot Studio kann der Begriff **Agent** verschiedene Arten von KI-Assistenten bezeichnen. Es ist hilfreich, eine Unterscheidung zu treffen zwischen:

**Konversationelle Agenten:**

- Konzentrieren sich hauptsÃ¤chlich auf den Dialog.  
- Behalten den Kontext Ã¼ber mehrere GesprÃ¤chsrunden hinweg.  
- Werden normalerweise Ã¼ber vordefinierte AblÃ¤ufe oder Trigger orchestriert (z. B. â€Wenn der Benutzer X sagt, antworte mit Yâ€œ).  
- Ideal fÃ¼r Kundensupport, FAQs, gefÃ¼hrte Interaktionen, Terminplanung oder einfache Q&A.  
  - Beispiele:
    - Ein Teams-Chatbot, der Fragen zu HR-Richtlinien beantwortet.  
    - Ein Power Virtual Agents-Bot auf einer SharePoint-Seite, der Benutzer durch ein Formular fÃ¼hrt.  

**Autonome Agenten:**

- Gehen Ã¼ber den Dialog hinaus; sie kÃ¶nnen **Handlungen** im Namen des Benutzers ausfÃ¼hren.  
- Nutzen LLM-Logikschleifen (denken Sie an â€Plan â†’ Handeln â†’ Beobachten â†’ Neu planenâ€œ), um Aufgaben zu erledigen.  
- Greifen auf externe Tools oder APIs zu (z. B. einen Power Automate-Flow ausfÃ¼hren, Kalendereinladungen senden, Daten in Dataverse manipulieren).  
- Arbeiten ohne stÃ¤ndige Benutzereingaben â€“ einmal ausgelÃ¶st, kÃ¶nnen sie mehrstufige Prozesse eigenstÃ¤ndig abwickeln.  
  - Beispiele:  
    - Ein Agent, der eine Reiseplanung erstellt, FlÃ¼ge bucht und BestÃ¤tigungen per E-Mail versendet.  
    - Ein â€Meeting-Zusammenfassungsâ€œ-Agent, der an einem Teams-Call teilnimmt, ihn in Echtzeit transkribiert und eine Zusammenfassung fÃ¼r OneNote erstellt.  

!!! Info "Wichtiger Unterschied"
    Konversationelle Agenten warten auf Benutzereingaben und bleiben beim Dialog. Autonome Agenten planen und fÃ¼hren proaktiv eine Reihe von Schritten aus, indem sie auf breitere ToolzugÃ¤nge zugreifen.

---

## Agenten in Copilot Studio

**Copilot Studio** vereint sowohl konversationelle als auch autonome Szenarien unter einem Framework. So hilft Ihnen Copilot Studio beim Erstellen von Agenten:

1. **Visueller Agenten-Designer:** Eine Low-Code-OberflÃ¤che, um Prompts, Speicher und Tools fÃ¼r Chat- und AktionsablÃ¤ufe zu definieren.  
1. **LLM-Konfigurationen:** WÃ¤hlen Sie aus verschiedenen OpenAI-Modellen oder Microsofts unternehmensgerechtem GPT, um Ihre Leistungs- und Kostenanforderungen zu erfÃ¼llen.  
1. **Retrieval-Connectoren:** Vorgefertigte Integrationen fÃ¼r SharePoint, OneDrive, Azure Cognitive Search und Dataverse, die RAG direkt unterstÃ¼tzen.  
1. **Benutzerdefinierte Tools & Funktionen:** Definieren Sie benutzerdefinierte HTTP-Aktionen oder Power Automate-Flows, die Ihr Agent autonom ausfÃ¼hren kann.  
1. **Multi-Modale UnterstÃ¼tzung:** Neben Text kÃ¶nnen Copilot Studio-Agenten Bilder, Dateien oder strukturierte Daten verarbeiten, um den Kontext zu bereichern.  
1. **VerÃ¶ffentlichung & Verteilung:** Sobald Ihr Agent fertig ist, kÃ¶nnen Sie ihn in Microsoft 365 Copilot verÃ¶ffentlichen (damit Benutzer ihn in Teams, SharePoint, Outlook usw. aufrufen) oder ihn als eigenstÃ¤ndiges Chat-Widget auf einer Webseite einbetten.

---

## ğŸ‰ Mission abgeschlossen

Sie haben nun Ihre EinfÃ¼hrung in Agenten und grundlegende KI-Konzepte abgeschlossen. Sie verstehen:

1. **LLMs = Das â€Gehirnâ€œ Ihres Agenten**  
   - Verantwortlich fÃ¼r SprachverstÃ¤ndnis und -generierung.  
   - Mehr Tokens = reichhaltigerer Kontext, aber auch hÃ¶here Kosten pro Aufruf.  

1. **RAG = Echtzeit-Wissensintegration**  
   - ÃœberbrÃ¼ckt die LÃ¼cke zwischen einem statischen LLM und sich stÃ¤ndig Ã¤ndernden Datenquellen.  
   - Ruft relevante Dokumente oder DatensÃ¤tze ab und fÃ¼gt sie dem LLM-Prompt hinzu.  

1. **Konversationell vs. Autonom**  
   - **Konversationell:** Fokus auf Dialogfluss und Kontextbewahrung (z. B. â€Sitzungsspeicherâ€œ).  
   - **Autonom:** HinzufÃ¼gen von â€AktionsblÃ¶ckenâ€œ, die es dem Agenten ermÃ¶glichen, externe Tools oder Dienste aufzurufen.

---
Als NÃ¤chstes erkunden Sie die [Grundlagen von Copilot Studio](../02-copilot-studio-fundamentals/README.md)!

Bleiben Sie wachsam, Rekrut â€“ Ihre KI-Reise hat gerade erst begonnen!

## ğŸ“š Taktische Ressourcen

ğŸ”— [Copilot Studio Dokumentations-Startseite](https://learn.microsoft.com/microsoft-copilot-studio/)

---

<!-- markdownlint-disable-next-line MD033 -->
<img src="https://m365-visitor-stats.azurewebsites.net/agent-academy/recruit/01-introduction-to-agents" alt="Analytics" />

---

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-Ãœbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) Ã¼bersetzt. Obwohl wir uns um Genauigkeit bemÃ¼hen, beachten Sie bitte, dass automatisierte Ãœbersetzungen Fehler oder Ungenauigkeiten enthalten kÃ¶nnen. Das Originaldokument in seiner ursprÃ¼nglichen Sprache sollte als maÃŸgebliche Quelle betrachtet werden. FÃ¼r kritische Informationen wird eine professionelle menschliche Ãœbersetzung empfohlen. Wir Ã¼bernehmen keine Haftung fÃ¼r MissverstÃ¤ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Ãœbersetzung ergeben.